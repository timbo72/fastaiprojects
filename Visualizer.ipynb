{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/henripal/maps/blob/master/nbs/big_resnet50-interpret-gradcam-dogs.ipynb\n",
    "https://github.com/henripal/maps/blob/master/nbs/big_resnet50-interpret-gradcam-sats.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will take the model from CatDogChickenBaby and play with some visualisations.\n",
    "The visualisations come from the [grad-cam](https://arxiv.org/abs/1610.02391) paper and would not have been possible (or even known) without the great work of [henripal](http://henripal.github.io/).\n",
    "\n",
    "Lets begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import re\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.0.22\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(fastai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad cam setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the paper for details. The idea is to take the outputs of the last \"convolutional layer\", here a stack of 7x7 feature maps, then weigh them by their importance to the given class using an average of the gradients of those layers wrt the class score vector.\n",
    "\n",
    "We therefore need to set up two hooks:\n",
    "\n",
    "for the feature maps\n",
    "for the gradient\n",
    "Then we linearly combine the feature maps using a reduced version of the gradient to obtain the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to use the output of the last Bottleneck as feature maps\n",
    "# this is hardcoded for resnet50\n",
    "target_layer = learn.model[0][7][2]\n",
    "target_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook for the feature maps\n",
    "fmap_hook = fastai.callbacks.hook_output(target_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook for the gradients \n",
    "def gradient_torch_hook(self, grad_input, grad_output):\n",
    "    return grad_input\n",
    "\n",
    "gradient_hook = fastai.callbacks.Hook(target_layer, gradient_torch_hook, is_forward=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad cam\n",
    "\n",
    "Our hooks are setup, let's run the forward and backward passes to get what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start by extracting a batch then choosing one image and label from that batch\n",
    "# i is the index of the chosen image\n",
    "i = 13\n",
    "image_batch, label_batch = next(iter(learn.data.train_dl))\n",
    "image = image_batch[i].reshape(1, 3, 224, 224)\n",
    "label = label_batch[i].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the forward pass\n",
    "learn.model.zero_grad();\n",
    "out = learn.model(image)\n",
    "\n",
    "# we need to set the gradients at the output to ones at the predicted class\n",
    "# and zero everywere else\n",
    "onehot = torch.zeros(learn.data.c)\n",
    "onehot[torch.argmax(out)] = 1.0\n",
    "\n",
    "# we then backprop from there\n",
    "out.backward(gradient=onehot.reshape(1, -1).cuda(), retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = next(iter(gradient_hook.stored))\n",
    "gradients.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now run our forward and backward passes, we only need to combine the gradients and feature maps to obtain our heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_linearization = gradients.cpu().numpy().sum((2, 3)).reshape(-1)\n",
    "fmaps = fmap_hook.stored.cpu().numpy()\n",
    "print(fmaps.shape)\n",
    "fmaps = fmaps.reshape(2048, 7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu on the heatmap\n",
    "heatmap = np.maximum(0, np.einsum('i, ijk',gradient_linearization, fmaps))\n",
    "\n",
    "# we now upsample the heatmap so we can overlay it on our original image\n",
    "upsampled = scipy.ndimage.zoom(heatmap, 32)\n",
    "upsampled = (upsampled - np.min(upsampled))/(np.max(upsampled) - np.min(upsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_from_tensor(imagetensor):\n",
    "    numpied = torch.squeeze(imagetensor)\n",
    "    numpied = np.moveaxis(numpied.cpu().numpy(), 0 , -1)\n",
    "    numpied = numpied - np.min(numpied)\n",
    "    numpied = numpied/np.max(numpied)\n",
    "    return numpied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_from_tensor(image))\n",
    "plt.imshow(upsampled, alpha=.8)\n",
    "plt.gca().set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our heatmap above is nice but unfortunately not very fine-grained. We are constrained by the resolution of the feature maps (in our example 7x7).\n",
    "\n",
    "A first idea would be to naively compute the backprop the gradients of our \"forced score\" all the way to the image, and see which pixel has higher gradients. So let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we ask the model to compute the gradients wrt the image:\n",
    "image.requires_grad_()\n",
    "\n",
    "# and then perform our forward and backward passes, forcing the gradient to be 1 for our predicted class\n",
    "out = learn.model(image)\n",
    "out.backward(gradient=onehot.reshape(1, -1).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_from_tensor(image.grad))\n",
    "plt.gca().set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks horrifying. This because the various neurons [interfere](https://en.wikipedia.org/wiki/Wave_interference) with each other during the backpropagation.\n",
    "\n",
    "The [Strving for Simplicity: the All Convolutional Net paper](https://arxiv.org/abs/1412.6806) introduced the concept of Guided Backpropagation. The idea, to avoid interference is to simply retain the positive contributions to the gradient while back-propaagating, thereby avoiding all interference.\n",
    "\n",
    "The idea is to clip all negative gradients at each ReLU layer. We will do this using the Hooks module in the fastai library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this callback will make all gradients positive during backprop\n",
    "def clamp_gradients_hook(module, grad_in, grad_out):\n",
    "    for grad in grad_in:\n",
    "        torch.clamp_(grad, min=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we inventory all Relu Modules\n",
    "relu_modules = [module[1] for module in learn.model.named_modules() if str(module[1]) == \"ReLU(inplace)\"]\n",
    "len(relu_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## and register our hooks with fastai\n",
    "hooks = fastai.callbacks.Hooks(relu_modules, clamp_gradients_hook, is_forward=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our hooks are registered, we will now backprop and observe the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval()\n",
    "image.requires_grad_()\n",
    "learn.model.zero_grad()\n",
    "out = learn.model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward(gradient=onehot.reshape(1, -1).cuda(), retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_from_tensor(image.grad))\n",
    "plt.gca().set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure we are only looking at relevant areas of the image, we will multiply this by the heatmap computed using Grad CAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbp =  image_from_tensor(image.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = np.einsum('ijk, ij->ijk',gbp, upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(prod)\n",
    "plt.gca().set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
